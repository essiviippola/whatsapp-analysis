{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"whatsapp-text-generation-lstm.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPyw7z1TQnD4F4KPwmM4xAa"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"fkFk7SjjkSzB"},"source":["# Whatsapp text generation with LSTM Recurrent Neural Network\r\n","\r\n","First (unsuccessful) attempt at generating text based on Whatsapp messages using deep learning.\r\n","\r\n","Ideas for improvement:\r\n","- Predicting words instead of characters. However, this might not work because the training data is in Finnish and contains loads of spoken language and typos.\r\n","- Using split messages instead of one large string\r\n","- Using UTF-8 characters instead of ASCII characters. Use emojis as single tokens.\r\n","- Remove punctuation as it is not typically used very much in Whatsapp messages\r\n","- Recuce batch size \r\n","\r\n","Source: https://machinelearningmastery.com/text-generation-lstm-recurrent-neural-networks-python-keras/ "]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"N_apa3J5kqiR","executionInfo":{"status":"ok","timestamp":1612119811097,"user_tz":-120,"elapsed":23885,"user":{"displayName":"Essi Viippola","photoUrl":"","userId":"15219457985143766510"}},"outputId":"69856a86-664d-41b8-f296-60c3f0176513"},"source":["# Setting up Google Colab\r\n","\r\n","from google.colab import drive\r\n","drive.mount(\"/content/gdrive\")\r\n","\r\n","%cd gdrive/My Drive/Projektit/whatsapp-analysis/src\r\n","\r\n","! pip install emoji"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/gdrive\n","/content/gdrive/My Drive/Projektit/whatsapp-analysis/src\n","Collecting emoji\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/24/fa/b3368f41b95a286f8d300e323449ab4e86b85334c2e0b477e94422b8ed0f/emoji-1.2.0-py3-none-any.whl (131kB)\n","\u001b[K     |████████████████████████████████| 133kB 7.3MB/s \n","\u001b[?25hInstalling collected packages: emoji\n","Successfully installed emoji-1.2.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"pP9BxWgJkRVP","executionInfo":{"status":"ok","timestamp":1612119816208,"user_tz":-120,"elapsed":28990,"user":{"displayName":"Essi Viippola","photoUrl":"","userId":"15219457985143766510"}}},"source":["# Import libraries\r\n","\r\n","import numpy as np\r\n","import sys\r\n","from whatsapp_analysis.config import data_path\r\n","from whatsapp_analysis.helper import import_data, preprocess_data\r\n","from keras.models import Sequential\r\n","from keras.layers import Dense, Dropout, LSTM\r\n","from keras.callbacks import ModelCheckpoint\r\n","from keras.utils import np_utils"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"Q9cD25jSl1eB","executionInfo":{"status":"ok","timestamp":1612119819039,"user_tz":-120,"elapsed":31817,"user":{"displayName":"Essi Viippola","photoUrl":"","userId":"15219457985143766510"}}},"source":["# Read and pre-process data\r\n","# - extract messages that are longer than 1 word and have no media or links\r\n","# - convert messages to lowercase\r\n","# - join messages to a single string\r\n","# - encode messages to ascii to make the dictionary smaller\r\n","\r\n","df = import_data(data_path)\r\n","df = preprocess_data(df)\r\n","messages = df[(df['media_count'] == 0) & (df['word_count'] > 1) & (df['link_count'] == 0)]['message']\r\n","messages = [message.lower() for message in messages]\r\n","text = ' '.join(messages)\r\n","text = text.encode('ascii', 'ignore').decode()"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"8LdVKvvcmJFq","executionInfo":{"status":"ok","timestamp":1612119819044,"user_tz":-120,"elapsed":31819,"user":{"displayName":"Essi Viippola","photoUrl":"","userId":"15219457985143766510"}}},"source":["# Creating a vocabulary and mapping characters to integers\r\n","\r\n","chars = sorted(list(set(text)))\r\n","char_to_int = dict((c, i) for i, c in enumerate(chars))"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ub9yry_LmRMH","executionInfo":{"status":"ok","timestamp":1612119819045,"user_tz":-120,"elapsed":31814,"user":{"displayName":"Essi Viippola","photoUrl":"","userId":"15219457985143766510"}},"outputId":"9928f85c-56fe-4034-8912-e633ebaed47d"},"source":["# Vocabulary statistics\r\n","\r\n","n_chars = len(text)\r\n","n_vocab = len(chars)\r\n","\r\n","print('Total characters:', n_chars)\r\n","print('Total vocab:', n_vocab)"],"execution_count":5,"outputs":[{"output_type":"stream","text":["Total characters: 1535411\n","Total vocab: 70\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ztm18cEymTb2","executionInfo":{"status":"ok","timestamp":1612119844820,"user_tz":-120,"elapsed":57583,"user":{"displayName":"Essi Viippola","photoUrl":"","userId":"15219457985143766510"}},"outputId":"5b173661-98e8-48c9-dc13-2ff01d0935ce"},"source":["# Prepare the dataset of input to output pairs encoded as integers\r\n","\r\n","seq_length = 100\r\n","dataX = []\r\n","datay = []\r\n","\r\n","for i in range(0, n_chars - seq_length, 1):\r\n","    seq_in = text[i:i+seq_length]\r\n","    seq_out = text[i+seq_length]\r\n","    dataX.append([char_to_int[char] for char in seq_in])\r\n","    datay.append(char_to_int[seq_out])\r\n","\r\n","n_patterns = len(dataX)\r\n","print('Total patterns:', n_patterns)\r\n","\r\n","X = np.reshape(dataX, (n_patterns, seq_length, 1))\r\n","X = X / float(n_vocab)\r\n","y = np_utils.to_categorical(datay)"],"execution_count":6,"outputs":[{"output_type":"stream","text":["Total patterns: 1535311\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"xsAfDMirmV36","executionInfo":{"status":"ok","timestamp":1612119850694,"user_tz":-120,"elapsed":63455,"user":{"displayName":"Essi Viippola","photoUrl":"","userId":"15219457985143766510"}}},"source":["# Define the LSTM model\r\n","\r\n","# Small model:\r\n","# model = Sequential()\r\n","# model.add(LSTM(256, input_shape=(X.shape[1], X.shape[2])))\r\n","# model.add(Dropout(0.2))\r\n","# model.add(Dense(y.shape[1], activation='softmax'))\r\n","# model.compile(loss='categorical_crossentropy', optimizer='adam')\r\n","\r\n","# Larger model:\r\n","\r\n","model = Sequential()\r\n","model.add(LSTM(256, input_shape=(X.shape[1], X.shape[2]), return_sequences=True))\r\n","model.add(Dropout(0.2))\r\n","model.add(LSTM(256))\r\n","model.add(Dropout(0.2))\r\n","model.add(Dense(y.shape[1], activation='softmax'))\r\n","model.compile(loss='categorical_crossentropy', optimizer='adam')\r\n","\r\n","# Define the checkpoint\r\n","\r\n","filepath = \"weights-improvement-{epoch:02d}-{loss:.4f}.hdf5\"\r\n","checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\r\n","callbacks_list = [checkpoint]"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tUTq2pMvmaDy","executionInfo":{"status":"ok","timestamp":1612123882067,"user_tz":-120,"elapsed":4094822,"user":{"displayName":"Essi Viippola","photoUrl":"","userId":"15219457985143766510"}},"outputId":"5cd7344a-9a73-4387-ba6b-4143d8d6a759"},"source":["# Fit the model\r\n","\r\n","model.fit(X, y, epochs=10, batch_size=128, callbacks=callbacks_list, verbose=1)"],"execution_count":8,"outputs":[{"output_type":"stream","text":["Epoch 1/10\n","11995/11995 [==============================] - 407s 33ms/step - loss: 2.6571\n","\n","Epoch 00001: loss improved from inf to 2.55548, saving model to weights-improvement-01-2.5555.hdf5\n","Epoch 2/10\n","11995/11995 [==============================] - 403s 34ms/step - loss: 2.3846\n","\n","Epoch 00002: loss improved from 2.55548 to 2.34724, saving model to weights-improvement-02-2.3472.hdf5\n","Epoch 3/10\n","11995/11995 [==============================] - 402s 34ms/step - loss: 2.2483\n","\n","Epoch 00003: loss improved from 2.34724 to 2.22933, saving model to weights-improvement-03-2.2293.hdf5\n","Epoch 4/10\n","11995/11995 [==============================] - 402s 33ms/step - loss: 2.1709\n","\n","Epoch 00004: loss improved from 2.22933 to 2.15877, saving model to weights-improvement-04-2.1588.hdf5\n","Epoch 5/10\n","11995/11995 [==============================] - 401s 33ms/step - loss: 2.1165\n","\n","Epoch 00005: loss improved from 2.15877 to 2.11106, saving model to weights-improvement-05-2.1111.hdf5\n","Epoch 6/10\n","11995/11995 [==============================] - 403s 34ms/step - loss: 2.0799\n","\n","Epoch 00006: loss improved from 2.11106 to 2.07563, saving model to weights-improvement-06-2.0756.hdf5\n","Epoch 7/10\n","11995/11995 [==============================] - 403s 34ms/step - loss: 2.0515\n","\n","Epoch 00007: loss improved from 2.07563 to 2.04816, saving model to weights-improvement-07-2.0482.hdf5\n","Epoch 8/10\n","11995/11995 [==============================] - 403s 34ms/step - loss: 2.0268\n","\n","Epoch 00008: loss improved from 2.04816 to 2.02598, saving model to weights-improvement-08-2.0260.hdf5\n","Epoch 9/10\n","11995/11995 [==============================] - 404s 34ms/step - loss: 2.0121\n","\n","Epoch 00009: loss improved from 2.02598 to 2.00941, saving model to weights-improvement-09-2.0094.hdf5\n","Epoch 10/10\n","11995/11995 [==============================] - 403s 34ms/step - loss: 1.9944\n","\n","Epoch 00010: loss improved from 2.00941 to 1.99339, saving model to weights-improvement-10-1.9934.hdf5\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7f0069344908>"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"s7ZWzMUJnG_c","executionInfo":{"status":"ok","timestamp":1612124783896,"user_tz":-120,"elapsed":4682,"user":{"displayName":"Essi Viippola","photoUrl":"","userId":"15219457985143766510"}},"outputId":"ae4ce14a-1911-4e62-affa-75b275b68ddb"},"source":["# Load the network weights\r\n","\r\n","filename = \"weights-improvement-10-1.9934.hdf5\"\r\n","model.load_weights(filename)\r\n","model.compile(loss='categorical_crossentropy', optimizer='adam')\r\n","\r\n","# Reverse mapping\r\n","\r\n","int_to_char = dict((i, c) for i, c in enumerate(chars))\r\n","\r\n","# Pick a random seed from messages\r\n","\r\n","start = np.random.randint(0, len(X)-1)\r\n","pattern = dataX[start]\r\n","\r\n","print('Seed:')\r\n","print(\"\\\"\", ''.join([int_to_char[value] for value in pattern]), \"\\\"\")\r\n","\r\n","# Generate characters\r\n","\r\n","print('Result:')\r\n","for i in range(100):\r\n","\tx = np.reshape(pattern, (1, len(pattern), 1))\r\n","\tx = x / float(n_vocab)\r\n","\tprediction = model.predict(x, verbose=0)\r\n","\tindex = np.argmax(prediction)\r\n","\tresult = int_to_char[index]\r\n","\tseq_in = [int_to_char[value] for value in pattern]\r\n","\tsys.stdout.write(result)\r\n","\tpattern.append(index)\r\n","\tpattern = pattern[1:len(pattern)]"],"execution_count":28,"outputs":[{"output_type":"stream","text":["Seed:\n","\" n maksaa softapivitykset? 0e huollon yhteydess no sit 5/5 iha jees toki huolto oli 169e mut ei ny ka \"\n","Result:\n","ikki tarvii kaikki tiet et se on koko tietoturvaittu kaikki tiet et se on kyll tiet et se on koko si"],"name":"stdout"}]}]}